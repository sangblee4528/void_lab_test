# ì§ˆë¬¸_native_loop_íë¦„ë„ (Flowchart)

ì´ ë¬¸ì„œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì…ë ¥ëœ í›„, ì—ì´ì „íŠ¸ê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³  ì˜¤ë¥˜ ë°œìƒ ì‹œ í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•´ ììœ¨ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ê¸°ìˆ ì ìœ¼ë¡œ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## 1. ì „ì²´ íë¦„ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
sequenceDiagram
    participant Void as Void IDE<br/>(ì±„íŒ…ì°½)
    participant Agent as agent_native_loop_server.py<br/>(127.0.0.1:8002)
    participant Tools as native_loop_tools.py<br/>(ë‚´ì¥ ë„êµ¬)
    participant DB as SQLite DB<br/>(agent_native_loop_data.db)
    participant LLM as Ollama/vLLM<br/>(127.0.0.1:11434)

    Void->>Agent: POST /v1/chat/completions<br/>{"messages": [{"role": "user", "content": "a.txt í™•ì¸í•´ì¤˜"}]}
    
    Note over Agent: chat_completions() ììœ¨ ë£¨í”„ ì‹œì‘
    
    loop Autonomous Loop (Max 5)
        Agent->>LLM: POST /v1/chat/completions<br/>(ëŒ€í™” ì´ë ¥ + Tools ì •ì˜)
        LLM-->>Agent: tool_calls: [{"name": "list_files", "args": {"path": "a.txt"}}]
        
        Agent->>Tools: list_files("a.txt") í˜¸ì¶œ
        
        alt íŒŒì¼ ì—†ìŒ (Error ë°œìƒ)
            Tools-->>Agent: {"success": false, "error": "file not found"}
            Note over Agent: ğŸ”„ Feedback Loop ì‘ë™
            Agent->>Agent: ì—ëŸ¬ ë¶„ì„ ë° í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±
            Agent->>LLM: "ì—ëŸ¬ ë°œìƒ: íŒŒì¼ ì—†ìŒ. ì–´ë–»ê²Œ í•´ê²°í• ë˜?"
            
            Note over LLM: í”¼ë“œë°± ìˆ˜ìš© ë° ìê°€ ìˆ˜ì •(Self-Correction)
            LLM-->>Agent: tool_calls: [{"name": "create_file", "args": {"filename": "a.txt"}}]
            
            Agent->>Tools: create_file("a.txt") í˜¸ì¶œ
            Tools-->>Agent: {"success": true, "message": "created"}
        else íŒŒì¼ ìˆìŒ
            Tools-->>Agent: {"success": true, "files": ["a.txt"]}
        end

        Agent->>LLM: ì‹¤í–‰ ê²°ê³¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ í˜¸ì¶œ
    end

    LLM-->>Agent: "íŒŒì¼ì´ ì—†ì–´ì„œ ìƒì„± í›„ í™•ì¸ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."
    Agent-->>Void: ìµœì¢… ì‘ë‹µ (SSE Stream)
```

---

## 2. ìƒì„¸ ë‹¨ê³„ë³„ íë¦„

### 1ï¸âƒ£ Void IDE â†’ Agent Loop Server

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (123í–‰)

```python
@app.post("/v1/chat/completions")
async def chat_completions(request: ChatRequest):
    # ìš”ì²­ ìˆ˜ì‹  ë° ë¡œê·¸ ì €ì¥
    request_id = datetime.now().strftime("%H%M%S")
    logger.info(f"ğŸ“¥ [Agent-{request_id}] ìƒˆ ìš”ì²­ ìˆ˜ì‹ : {request.messages[-1].content}")
    save_agent_log(request_id, "Request Received", request.messages[-1].content)
    
    current_messages = [msg.model_dump(exclude_none=True) for msg in request.messages]
```

**ìš”ì²­ ë°ì´í„°**:
```json
{
  "messages": [
    {"role": "user", "content": "a.txt í™•ì¸í•´ì¤˜"}
  ],
  "stream": true
}
```

---

### 2ï¸âƒ£ ë„êµ¬ ëª©ë¡ ë¡œë“œ ë° LLM í˜¸ì¶œ ì¤€ë¹„

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (135-140í–‰)

```python
# ë„êµ¬ ëª©ë¡ ë¡œë“œ (ë¡œì»¬ native_tools ì‚¬ìš©)
tools = request.tools
if not tools:
    logger.info(f"ğŸ” [Agent-{request_id}] ë¡œì»¬ ë„¤ì´í‹°ë¸Œ ë„êµ¬ ëª©ë¡ ì‚¬ìš© ì¤‘...")
    tools = NATIVE_TOOL_DEFS # native_loop_tools.pyì—ì„œ ì •ì˜ëœ ë„êµ¬
```

---

### 3ï¸âƒ£ ììœ¨ ì‹¤í–‰ ë£¨í”„ (Autonomous Loop)

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (146-153í–‰)

```python
# n8n ìŠ¤íƒ€ì¼ì˜ ìƒíƒœ ë¨¸ì‹  ë£¨í”„
max_iterations = 5
for i in range(max_iterations):
    # status 1: Thinking
    logger.info(f"ğŸ“¤ [Agent-{request_id}] [LLM REQ] LLMì—ê²Œ ë‹µë³€ ìš”ì²­ ì¤‘...")
    full_ollama_resp = await call_llm(current_messages, tools)
```

---

### 4ï¸âƒ£ LLM ì‘ë‹µ ë¶„ì„ ë° JSON ì¶”ì¶œ (Output Parsing)

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (165-206í–‰)

Ollamaì™€ ê°™ì€ ëª¨ë¸ì´ ê·œê²©í™”ëœ `tool_calls` ëŒ€ì‹  í…ìŠ¤íŠ¸ ë‚´ì— JSONìœ¼ë¡œ ë‹µë³€í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ íŒŒì‹± ë¡œì§ì…ë‹ˆë‹¤.

```python
if not tool_calls and content:
    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° ë° JSON ì¶”ì¶œ ì‹œë„
    if "{" in json_str and "}" in json_str:
        # ì¤‘ê´„í˜¸ ë²”ìœ„ë¥¼ ì°¾ì•„ JSONë§Œ ì¶”ì¶œ
        potential_tool = json.loads(json_str)
        if "name" in potential_tool and "arguments" in potential_tool:
            tool_calls = [{"function": potential_tool}]
```

---

### 5ï¸âƒ£ ë¡œì»¬ ë„¤ì´í‹°ë¸Œ ë„êµ¬ ì§ì ‘ ì‹¤í–‰ (Action)

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (243-254í–‰)

**íŒŒì¼**: `agent_native_loop/native_loop_tools.py` (ì‹¤ì œ êµ¬í˜„ë¶€)

```python
# Server: ë„êµ¬ ë§¤í•‘ ë° ì‹¤í–‰
if func_name in NATIVE_TOOL_REGISTRY:
    result = NATIVE_TOOL_REGISTRY[func_name](**args)

# Tools: ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ (list_files)
def list_files(path: str = ".") -> Dict[str, Any]:
    p = Path(path)
    if not p.exists():
        return {"success": False, "error": f"Path '{path}' does not exist"}
    files = [f.name for f in p.iterdir() if f.is_file()]
    return {"success": True, "files": files}
```

---

### 6ï¸âƒ£ í”¼ë“œë°± ë£¨í”„ ì‘ë™ (Feedback Loop)

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `chat_completions()` (260-276í–‰)

ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ LLMì—ê²Œ ëª…ì‹œì ì¸ í”¼ë“œë°±ì„ ì£¼ì–´ ìê°€ ìˆ˜ì •ì„ ìœ ë„í•©ë‹ˆë‹¤.

```python
if not result.get("success", True):
    error_msg = result.get("error", "Unknown error")
    feedback_content = f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}\nì›ì¸ì„ ë¶„ì„í•˜ê³  í•„ìš”í•œ ê²½ìš° ìˆ˜ì •ëœ ì¸ìë¡œ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì°¾ì•„ì£¼ì„¸ìš”."
    current_messages.append({
        "role": "tool",
        "tool_call_id": call_id,
        "content": json.dumps({"status": "error", "message": feedback_content}, ensure_ascii=False)
    })
```

---

### 7ï¸âƒ£ ìµœì¢… ì‘ë‹µ ë° ìŠ¤íŠ¸ë¦¬ë° ë°˜í™˜

**íŒŒì¼**: `agent_native_loop/agent_native_loop_server.py`  
**í•¨ìˆ˜**: `generate_pseudo_stream()` (315í–‰)

```python
def generate_pseudo_stream(final_resp: Dict):
    # OpenAI ê·œê²©ì˜ SSE ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    yield f"data: {json.dumps(chunk1, ensure_ascii=False)}\n\n"
    yield f"data: {json.dumps(chunk2, ensure_ascii=False)}\n\n"
    yield f"data: {json.dumps(chunk3, ensure_ascii=False)}\n\n"
    yield "data: [DONE]\n\n"
```

---

## 3. í•µì‹¬ êµ¬ì„± ìš”ì†Œ ìš”ì•½

*   **ììœ¨ì„±**: ì‚¬ìš©ì ê°œì… ì—†ì´ ìµœëŒ€ 5íšŒê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê³  ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
*   **ìê°€ ìˆ˜ì •**: ì‹¤íŒ¨ë¥¼ ì„±ê³µì˜ ë°œíŒìœ¼ë¡œ ì‚¼ì•„ ì „ëµì„ ìˆ˜ì •í•˜ëŠ” í”¼ë“œë°± ë£¨í”„ë¥¼ íƒ‘ì¬í–ˆìŠµë‹ˆë‹¤.
*   **ê³ ì„±ëŠ¥**: ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ì´ ì„œë²„ ë‚´ì—ì„œ ì¦‰ì‹œ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
